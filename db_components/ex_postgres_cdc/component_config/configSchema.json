{
  "type": "object",
  "title": "Authorization",
  "required": [
    "db_settings"
  ],
  "properties": {
    "db_settings": {
      "type": "object",
      "format": "grid-strict",
      "title": "Authorization",
      "description": "The connector is based on Debezium Connector, for the Postgres setup follow the official <a href=\"https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-permissions\">instructions</a>",
      "required": [
        "#password",
        "host",
        "port",
        "user",
        "database"
      ],
      "properties": {
        "host": {
          "type": "string",
          "title": "Hostname",
          "propertyOrder": 1,
          "options": {
            "grid_columns": 8
          }
        },
        "port": {
          "type": "integer",
          "title": "Port",
          "default": 5432,
          "propertyOrder": 10,
          "options": {
            "grid_columns": 4
          }
        },
        "user": {
          "type": "string",
          "title": "User",
          "propertyOrder": 20,
          "options": {
            "grid_columns": 12
          }
        },
        "#password": {
          "type": "string",
          "title": "Password",
          "format": "password",
          "propertyOrder": 40,
          "options": {
            "grid_columns": 12
          }
        },
        "database": {
          "type": "string",
          "title": "Database",
          "propertyOrder": 50,
          "options": {
            "grid_columns": 12
          }
        },
        "ssh_options": {
          "type": "object",
          "format": "ssh-editor",
          "propertyOrder": 60
        },
        "test_connection": {
          "type": "button",
          "format": "test-connection",
          "propertyOrder": 500
        }
      },
      "propertyOrder": 1
    },
    "source_settings": {
      "title": "Data Source",
      "type": "object",
      "propertyOrder": 10,
      "properties": {
        "schemas": {
          "type": "array",
          "title": "Schemas",
          "items": {
            "enum": [],
            "type": "string"
          },
          "format": "select",
          "uniqueItems": true,
          "options": {
            "async": {
              "label": "Re-load schemas",
              "action": "get_schemas",
              "autoload": [
                "parameters.db_settings.user",
                "parameters.db_settings.#password",
                "parameters.db_settings.database"
              ]
            }
          },
          "propertyOrder": 100
        },
        "tables": {
          "type": "array",
          "title": "Tables to sync",
          "description": "If left empty all tables are synced.",
          "items": {
            "enum": [],
            "type": "string"
          },
          "format": "select",
          "uniqueItems": true,
          "options": {
            "async": {
              "label": "Re-load tables",
              "action": "get_tables",
              "autoload": [
                "parameters.source_settings.schemas"
              ]
            }
          },
          "propertyOrder": 102
        },
        "column_filter_type": {
          "type": "string",
          "title": "Column Filter Type",
          "description": "If not specified all columns are synced. Define filters as list of regular expressions that match the fully-qualified names of columns that should be included or excluded from change event record values.",
          "enum": [
            "none",
            "exclude",
            "include"
          ],
          "default": "none",
          "propertyOrder": 103
        },
        "column_filter": {
          "title": "Column List",
          "type": "array",
          "format": "select",
          "uniqueItems": true,
          "options": {
            "dependencies": {
              "column_filter_type": [
                "exclude",
                "include"
              ]
            },
            "tags": true,
            "tooltip": "(comma separated list) of fully-qualified names for columns are of the form `schemaName.tableName.columnName`.\n\nTo match the name of a column, connector applies the regular expression that you specify as an **anchored regular expression**. That is, the expression is used to match the entire name string of the column; it does not match substrings that might be present in a column name.",
            "inputAttributes": {
              "placeholder": "schemaName.tableName.columnName"
            }
          },
          "description": "Define filters as list of regular expressions that match the fully-qualified names of columns that should be filtered in change event record values.",
          "items": {
            "type": "string"
          },
          "propertyOrder": 105
        }
      }
    },
    "sync_options": {
      "title": "Sync Options",
      "type": "object",
      "required": [
        "source_signal_table",
        "snapshot_mode"
      ],
      "propertyOrder": 15,
      "properties": {
        "source_signal_table": {
          "title": "Signalling Table",
          "propertyOrder": 1,
          "type": "string",
          "description": "A system signal table that will be used by to connector to store various signal events and incremental snapshot watermarks.",
          "enum": [],
          "format": "select",
          "options": {
            "tooltip": "You need to create a signaling table by submitting a standard SQL DDL query to the source database. \n\nThe following example shows a `CREATE TABLE` command that creates a three-column `debezium_signal` table: \n\n```sql\nCREATE TABLE debezium_signal (id VARCHAR(42) PRIMARY KEY, type VARCHAR(32) NOT NULL, data VARCHAR(2048) NULL);\n``` \n\n **Note** that the connector must have write access to the signaling table.",
            "async": {
              "label": "Re-load tables",
              "action": "get_tables",
              "autoload": [
                "parameters.source_settings.schemas"
              ]
            }
          }
        },
        "snapshot_mode": {
          "type": "string",
          "title": "Replication Mode",
          "description": "The mode 'Changes Only' will skip the initial full sync. Standard mode performs full sync of the tables on the first run.",
          "propertyOrder": 5,
          "enum": [
            "initial",
            "never"
          ],
          "options": {
            "enum_titles": [
              "Standard",
              "Changes only"
            ]
          }
        },
        "snapshot_fetch_size": {
          "type": "integer",
          "title": "Snapshot Fetch Size",
          "description": "During a snapshot, the connector reads table content in batches of rows. This property specifies the maximum number of rows in a batch.",
          "default": 10240,
          "propertyOrder": 20
        },
        "snapshot_threads": {
          "type": "integer",
          "title": "Snapshot parallelism",
          "description": "Specifies the number of threads that the connector uses when performing an initial snapshot. To enable parallel initial snapshots, set the property to a value greater than 1. In a parallel initial snapshot, the connector processes multiple tables concurrently.",
          "default": 1,
          "propertyOrder": 30
        },
        "enable_heartbeat": {
          "type": "boolean",
          "title": "Enable Heartbeat",
          "description": "Enables the heartbeat signal that is used to prevent WAL disk space overflow when tracking low transaction tables.",
          "default": false,
          "propertyOrder": 40
        },
        "heartbeat_config": {
          "type": "object",
          "title": "Heartbeat Configuration",
          "options": {
            "dependencies": {
              "enable_heartbeat": true
            },
            "tooltip": "This configuration avoids PostgreSQL disk space consumed by WAL files to spike or increase out of usual proportions that can happen in following scenarios:\n\n- There are many updates in a database that is being tracked but only a tiny number of updates are related to the table(s) and schema(s) for which the connector is capturing changes. This situation can be easily solved with periodic heartbeat events.\n- The PostgreSQL instance contains multiple databases and one of them is a high-traffic database. Debezium captures changes in another database that is low-traffic in comparison to the other database. Debezium then cannot confirm the LSN as replication slots work per-database and Debezium is not invoked. As WAL is shared by all databases, the amount used tends to grow until an event is emitted by the database for which Debezium is capturing changes. \n"
          },
          "propertyOrder": 50,
          "properties": {
            "interval_ms": {
              "type": "integer",
              "title": "Heartbeat Interval [ms]",
              "description": "The interval in milliseconds at which the connector performs the heartbeat action in the source database. If you observe that the heartbeat is not emitted during connector run, you can decrease the interval.",
              "default": 3000,
              "propertyOrder": 10
            },
            "action_query": {
              "type": "string",
              "title": "Action Query",
              "options": {
                "tooltip": "This query will be sent regularly by the connector in the specified Heartbeat interval. **Note that the table must exist** in the source database and be tracked by the connector. \n\n The recommended schema is:  \n\n ```sql\nCREATE SCHEMA IF NOT EXISTS kbc;\nCREATE TABLE kbc.heartbeat (id SERIAL PRIMARY KEY, last_heartbeat TIMESTAMP NOT NULL DEFAULT NOW());\nINSERT INTO kbc.heartbeat (last_heartbeat) VALUES (NOW());\n``` \n\n For more information please refer to the documentation."
              },
              "description": "The query that the connector uses to send heartbeat signals to the source database. The query must be a valid SQL statement that the source database can execute and the heartbeat table must be tracked in the Source settings.",
              "default": "UPDATE kbc.heartbeat SET last_heartbeat = NOW()",
              "propertyOrder": 20
            }
          }
        }
      }
    },
    "destination": {
      "title": "Destination",
      "type": "object",
      "propertyOrder": 600,
      "required": [
        "load_type"
      ],
      "properties": {
        "load_type": {
          "enum": [
            "incremental_load",
            "full_load",
            "append_incremental",
            "append_full"
          ],
          "type": "string",
          "title": "Load Type",
          "default": "incremental_load",
          "options": {
            "tooltip": "Append modes do not perform deduplication and do not set output table primary key. The result tables will include additional columns: `KBC__EVENT_TIMESTAMP_MS` and `KBC__BATCH_EVENT_ORDER`. \n\n **Note** that changing this parameter after the initial run **may result in errors and drop of the existing tables is recommended** prior changing this parameter.",
            "enum_titles": [
              "Incremental Load - Deduplicated",
              "Full Load - Deduplicated",
              "Incremental Load - Append",
              "Full Load - Append"
            ]
          },
          "description": "If Full load is used, the destination table will be overwritten every run. If Incremental Load is used, data will be upserted into the destination table based on the primary key. Append modes do not contain any primary keys and are not deduplicated.",
          "propertyOrder": 30
        }
      }
    }
  }
}