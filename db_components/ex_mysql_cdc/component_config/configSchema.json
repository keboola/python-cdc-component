{
  "type": "object",
  "title": "Authorization",
  "required": [
    "db_settings"
  ],
  "properties": {
    "db_settings": {
      "type": "object",
      "format": "grid-strict",
      "title": "Connection Settings",
      "required": [
        "#password",
        "host",
        "port",
        "user"
      ],
      "properties": {
        "host": {
          "type": "string",
          "title": "Hostname",
          "propertyOrder": 1,
          "options": {
            "grid_columns": 8
          }
        },
        "port": {
          "type": "integer",
          "title": "Port",
          "default": 5432,
          "propertyOrder": 10,
          "options": {
            "grid_columns": 4
          }
        },
        "user": {
          "type": "string",
          "title": "User",
          "propertyOrder": 20,
          "options": {
            "grid_columns": 12
          }
        },
        "#password": {
          "type": "string",
          "title": "Password",
          "format": "password",
          "propertyOrder": 40,
          "options": {
            "grid_columns": 12
          }
        },
        "ssh_options": {
          "type": "object",
          "format": "ssh-editor",
          "propertyOrder": 60
        },
        "test_connection": {
          "type": "button",
          "format": "test-connection",
          "propertyOrder": 500
        }
      },
      "propertyOrder": 1
    },
    "source_settings": {
      "title": "Data Source",
      "type": "object",
      "propertyOrder": 10,
      "properties": {
        "schemas": {
          "type": "array",
          "title": "Schemas",
          "items": {
            "enum": [],
            "type": "string"
          },
          "format": "select",
          "uniqueItems": true,
          "options": {
            "tags": true,
            "async": {
              "label": "Re-load schemas",
              "action": "get_schemas",
              "autoload": [
                "parameters.db_settings.user",
                "parameters.db_settings.#password",
                "parameters.db_settings.database"
              ]
            }
          },
          "propertyOrder": 100
        },
        "tables": {
          "type": "array",
          "title": "Tables to sync",
          "description": "If left empty all tables are synced.",
          "items": {
            "enum": [],
            "type": "string"
          },
          "format": "select",
          "uniqueItems": true,
          "options": {
            "tags": true,
            "async": {
              "label": "Re-load tables",
              "action": "get_tables",
              "autoload": [
                "parameters.source_settings.schemas"
              ]
            }
          },
          "propertyOrder": 102
        },
        "column_filter_type": {
          "type": "string",
          "title": "Column Filter Type",
          "description": "If not specified all columns are synced. Define filters as list of regular expressions that match the fully-qualified names of columns that should be included or excluded from change event record values.",
          "enum": [
            "none",
            "exclude",
            "include"
          ],
          "default": "none",
          "propertyOrder": 103
        },
        "column_filter": {
          "title": "Column List",
          "type": "array",
          "format": "select",
          "uniqueItems": true,
          "options": {
            "dependencies": {
              "column_filter_type": [
                "exclude",
                "include"
              ]
            },
            "tags": true,
            "tooltip": "(comma separated list) of fully-qualified names for columns are of the form `schemaName.tableName.columnName`.\n\nTo match the name of a column, connector applies the regular expression that you specify as an **anchored regular expression**. That is, the expression is used to match the entire name string of the column; it does not match substrings that might be present in a column name.",
            "inputAttributes": {
              "placeholder": "schemaName.tableName.columnName"
            }
          },
          "description": "Define filters as list of regular expressions that match the fully-qualified names of columns that should be filtered in change event record values.",
          "items": {
            "type": "string"
          },
          "propertyOrder": 105
        }
      }
    },
    "sync_options": {
      "title": "Sync Options",
      "type": "object",
      "required": [
        "source_signal_table",
        "snapshot_mode"
      ],
      "propertyOrder": 15,
      "properties": {
        "source_signal_table": {
          "title": "Signalling Table",
          "propertyOrder": 1,
          "type": "string",
          "default": "",
          "description": "A system signal table that will be used by to connector to store various signal events and incremental snapshot watermarks.",
          "enum": [],
          "format": "select",
          "options": {
            "tooltip": "You need to create a signaling table by submitting a standard SQL DDL query to the source database. \n\nThe following example shows a `CREATE TABLE` command that creates a three-column `debezium_signal` table: \n\n```sql\nCREATE TABLE debezium_signal (id VARCHAR(42) PRIMARY KEY, type VARCHAR(32) NOT NULL, data TEXT NULL);\n``` \n\n **Note** that the connector must have write access to the signaling table.",
            "async": {
              "label": "Re-load tables",
              "action": "get_tables",
              "autoload": [
                "parameters.source_settings.schemas"
              ]
            }
          }
        },
        "snapshot_mode": {
          "type": "string",
          "title": "Replication Mode",
          "description": "The mode 'Changes Only' will skip the initial full sync. Standard mode performs full sync of the tables on the first run.",
          "propertyOrder": 5,
          "enum": [
            "initial",
            "never"
          ],
          "options": {
            "enum_titles": [
              "Standard",
              "Changes only"
            ]
          }
        },
        "snapshot_fetch_size": {
          "type": "integer",
          "title": "Snapshot Fetch Size",
          "description": "During a snapshot, the connector reads table content in batches of rows. This property specifies the maximum number of rows in a batch.",
          "default": 10240,
          "propertyOrder": 20
        },
        "snapshot_threads": {
          "type": "integer",
          "title": "Snapshot parallelism",
          "description": "Specifies the number of threads that the connector uses when performing an initial snapshot. To enable parallel initial snapshots, set the property to a value greater than 1. In a parallel initial snapshot, the connector processes multiple tables concurrently.",
          "default": 4,
          "propertyOrder": 30
        },
        "handle_binary": {
          "propertyOrder": 2,
          "type": "string",
          "title": "Binary data handler",
          "default": "hex",
          "enum": [
            "bytes",
            "hex",
            "base64",
            "base64-url-safe"
          ],
          "description": "Marks how to handle binary data:<ul><li><strong>plain</strong> - data in decoded from binary to string using Python's <i><a href='https://docs.python.org/3/library/stdtypes.html#bytes.decode' target='_blank'>bytes.decode()</a></i> method,</li><li><strong>hex</strong> - data is converted to hex representation of binary string using <i><a href='https://docs.python.org/3/library/stdtypes.html#bytes.hex' target='_blank'>bytes.hex()</a></i> method,</li><li><strong>base64</strong> - data is converted to a base64 string, using <i><a href='https://docs.python.org/3/library/base64.html#base64.b64encode' target='_blank'>base64.b64encode()</a></i> method.</li></ul>All trailing or leading null bytes are replaced."
        }
      }
    },
    "destination": {
      "title": "Destination",
      "type": "object",
      "propertyOrder": 600,
      "required": [
        "load_type"
      ],
      "properties": {
        "load_type": {
          "enum": [
            "incremental_load",
            "full_load",
            "append_incremental",
            "append_full"
          ],
          "type": "string",
          "title": "Load Type",
          "default": "incremental_load",
          "options": {
            "tooltip": "Append modes do not perform deduplication and do not set output table primary key. The result tables will include additional columns: `KBC__EVENT_TIMESTAMP_MS` and `KBC__BATCH_EVENT_ORDER`. \n\n **Note** that changing this parameter after the initial run **may result in errors and drop of the existing tables is recommended** prior changing this parameter.",
            "enum_titles": [
              "Incremental Load - Deduplicated",
              "Full Load - Deduplicated",
              "Incremental Load - Append",
              "Full Load - Append"
            ]
          },
          "description": "If Full load is used, the destination table will be overwritten every run. If Incremental Load is used, data will be upserted into the destination table based on the primary key. Append modes do not contain any primary keys and are not deduplicated.",
          "propertyOrder": 30
        },
        "outputBucket": {
          "type": "string",
          "title": "Output Bucket",
          "default": "",
          "options": {
            "tooltip": "Specify the bucket name **without the stage prefix**. The default bucket name will be used if empty. The result bucket path will be `in.c-<bucket_name>`",
            "placeholder": "my-bucket"
          },
          "description": "(Optional) The name of bucket in Keboola (without the stage prefix) storage where the data. Keboola will create a bucket for you if not specified. The result bucket path will be `in.c-<bucket_name>",
          "propertyOrder": 200
        }
      }
    }
  }
}